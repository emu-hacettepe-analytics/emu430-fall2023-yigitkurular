city_population = c(4.300.000, 16.000.000, 5.700.000)
Turkish_cities <- data.frame(
city_name = c("Izmir", "Istanbul", "Ankara"),
city_population = c("4.300.000", "16.000.000", "5.700.000")
)
View(Turkish_cities)
reticulate::repl_python()
import pandas as pd
turkish_cities= [["Izmır", 4.300.000], ["Istanbul", 16.000.000], ["Ankara", 5.700.000]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
df
View(turkish_cities)
View(Turkish_cities)
import pandas as pd
turkish_cities= [["Izmır", 4.300.000], ["Istanbul", 16.000.000], ["Ankara", 5.700.000]]
df= pd.dataframe(turkish_cities,columns= ["city_name", city_population])
df
import pandas as pd
turkish_cities= [["Izmır", 4.300.000], ["Istanbul", 16.000.000], ["Ankara", 5.700.000]]
df= pd.dataframe(turkish_cities,columns= ["city_name", city_population])
import pandas as pd
turkish_cities= [["Izmır", 4.300.000], ["Istanbul", 16.000.000], ["Ankara", 5.700.000]]
df= pd.dataframe(turkish_cities,columns= ["city_name", city_population])
import pandas as pd
turkish_cities= [["Izmır", 4.300.000], ["Istanbul", 16.000.000], ["Ankara", 5.700.000]]
df= pd.dataframe(turkish_cities,columns= ["city_name", city_population])
import pandas as pd
turkish_cities= [["Izmır", 4.300.000], ["Istanbul", 16.000.000], ["Ankara", 5.700.000]]
df= pd.dataframe(turkish_cities,columns= ["city_name", city_population])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
import pandas as pd
turkish_cities= [["Izmır", "4.300.000"], ["Istanbul", "16.000.000"], ["Ankara", "5.700.000"]]
df= pd.dataframe(turkish_cities,columns= ["city_name", "city_population"])
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
title <- c()
year <- c()
duration <- c()
rating <- c()
vote <- c()
for (url in sum_url) {
page <- read_html(url)
# To extract names
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) { x[2] }))
title <- append(title, title_names)
# To extract years
years <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year <- append(year, years)
# To convert durations
convert_duration_to_minutes <- function(duration_string) {
hours <- as.numeric(str_extract(duration_string, "\\d+\\s?h"))
minutes <- as.numeric(str_extract(duration_string, "\\d+\\s?m"))
seconds <- as.numeric(str_extract(duration_string, "\\d+\\s?s"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
seconds <- ifelse(is.na(seconds), 0, seconds)
total_minutes <- hours * 60 + minutes + seconds / 60
return(total_minutes)
}
# To extract durations
durations <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text()
convert_to_minutes <- function(duration) {
hours <- as.numeric(str_extract(duration, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(duration, "\\d+(?=m)"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_in_minutes <- lapply(durations, function(d) {
d <- str_extract(d, "\\d+h( \\d+m)?|\\d+m|\\d+") %>% str_extract("(?<=^.{4}).*")
convert_to_minutes(d)
})
durations <- unlist(durations_in_minutes)
duration <- append(duration, durations)
# To extract ratings
ratings <- page %>% html_nodes(".sc-43986a27-1.fVmjht") %>% html_text() %>% str_sub(1, 3) %>% as.numeric()
rating <- append(rating, ratings)
# To extract votes
votes <- page %>% html_nodes(".sc-53c98e73-0.kRnqtn") %>% html_text() %>% str_extract_all("\\d+") %>% sapply(function(x) as.numeric(paste(x, collapse = "")))
vote <- append(vote, votes)
}
movies_df <- data.frame(title, year, duration, rating, vote)
head(movies_df)
movies_df <- movies_df[order(-movies_df$rating), ]
best_5_movies <- head(movies_df, 5)
print("Best 5 Movies:")
print(best_5_movies)
movies_df <- movies_df[order(-movies_df$rating), ]
worst_5_movies <- tail(movies_df, 5)
print("Worst 5 Movies:")
print(worst_5_movies)
movies_df %>% filter(title == "Aile Arasinda" | title == "Babam ve Oglum" | title == "G.O.R.A." | title == "Pek Yakinda" | title == "Beyaz Melek") %>% arrange(desc(rating))
movie_count_by_year <- movies_df %>%
group_by(year) %>%
summarise(count = n())
# Plot the graph
ggplot(movie_count_by_year, aes(x = year, y = count)) + geom_point(size = 1) + labs(title = "Number of Movies by Year", x = "Year", y = "Number of Movies")
ratings_by_year <- movies_df %>% group_by(year) %>% summarise(average_rating = mean(rating))
# Plot the graph
ggplot(average_ratings_by_year, aes(x = year, y = average_rating)) + geom_point(size = 1) + labs(title = "Average Ratings by Year", x = "Year", y = "Average Rating")
ratings_by_year <- movies_df %>% group_by(year) %>% summarise(average_rating = mean(rating))
# Plot the graph
ggplot(ratings_by_year, aes(x = year, y = average_rating)) + geom_point(size = 1) + labs(title = "Average Ratings by Year", x = "Year", y = "Average Rating")
ratings_by_year <- movies_df %>% group_by(year) %>% summarise(average_rating = mean(rating))
# Plot the graph
ggplot(average_ratings_by_year, aes(x = year, y = average_rating)) + geom_point(size = 1) + labs(title = "Average Ratings by Year", x = "Year", y = "Average Rating")
ratings_by_year <- movies_df %>% group_by(year) %>% summarise(average_rating = mean(rating))
# Plot the graph
ggplot(ratings_by_year, aes(x = year, y = average_rating)) + geom_point(size = 1) + labs(title = "Average Ratings by Year", x = "Year", y = "Average Rating")
ggplot(movies_df, aes(x = vote, y = rating)) + geom_point() + labs(x = "Votes", y = "Ratings")
ggplot(movies_df, aes(x = duration, y = rating)) + geom_point() + labs(x = "Duration (minutes)", y = "Rating")
library(tidyverse)
library(stringr)
library(rvest)
url_new <- "https://www.imdb.com/search/title/?groups=top_1000&country_of_origin=TR"
title_new <- c()
year_new <- c()
for (url in url_new) {
page <- read_html(url)
# To extract names
title_names_new <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names_new <- tail(head(title_names_new, -1), -1)
title_names_new <- str_split(title_names_new, " ", n = 2)
title_names_new <- unlist(lapply(title_names_new, function(x) { x[2] }))
title_new <- append(title_new, title_names_new)
# To extract years
years_new <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year_new <- append(year_new, years_new)
}
movies_df_new <- data.frame(title_new, year_new)
library(tidyverse)
library(stringr)
library(rvest)
url_new <- "https://www.imdb.com/search/title/?groups=top_1000&country_of_origin=TR"
title_new <- c()
year_new <- c()
for (url in url_new) {
page <- read_html(url)
# To extract names
title_names_new <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names_new <- tail(head(title_names_new, -1), -1)
title_names_new <- str_split(title_names_new, " ", n = 2)
title_names_new <- unlist(lapply(title_names_new, function(x) { x[2] }))
title_new <- append(title_new, title_names_new)
# To extract years
years_new <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year_new <- append(year_new, years_new)
}
movies_df_new <- data.frame(title_new, year_new)
movies_df_new
library(dplyr)
result_df <- left_join(movies_df_new, movies_df, by = c("title_new" = "title"))
print(result_df)
library(dplyr)
ranked_movies_joined <- result_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movied_joined)
library(dplyr)
ranked_movies_joined <- result_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movied_joined)
library(dplyr)
result_df <- left_join(movies_df_new, movies_df, by = c("title_new" = "title"))
print(result_df)
library(dplyr)
ranked_movies_joined <- result_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movied_joined)
library(dplyr)
ranked_movies_joined <- result_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movied_joined)
library(dplyr)
ranked_movies_joined <- result_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movies_joined)
library(dplyr)
ranked_movies_initial <- movies_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movies_initial)
library(dplyr)
ranked_movies_initial <- movies_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movies_initial)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
title <- c()
year <- c()
duration <- c()
rating <- c()
vote <- c()
for (url in sum_url) {
page <- read_html(url)
# To extract names
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) { x[2] }))
title <- append(title, title_names)
# To extract years
years <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year <- append(year, years)
# To convert durations
convert_duration_to_minutes <- function(duration_string) {
hours <- as.numeric(str_extract(duration_string, "\\d+\\s?h"))
minutes <- as.numeric(str_extract(duration_string, "\\d+\\s?m"))
seconds <- as.numeric(str_extract(duration_string, "\\d+\\s?s"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
seconds <- ifelse(is.na(seconds), 0, seconds)
total_minutes <- hours * 60 + minutes + seconds / 60
return(total_minutes)
}
# To extract durations
durations <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text()
convert_to_minutes <- function(duration) {
hours <- as.numeric(str_extract(duration, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(duration, "\\d+(?=m)"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_in_minutes <- lapply(durations, function(d) {
d <- str_extract(d, "\\d+h( \\d+m)?|\\d+m|\\d+") %>% str_extract("(?<=^.{4}).*")
convert_to_minutes(d)
})
durations <- unlist(durations_in_minutes)
duration <- append(duration, durations)
# To extract ratings
ratings <- page %>% html_nodes(".sc-43986a27-1.fVmjht") %>% html_text() %>% str_sub(1, 3) %>% as.numeric()
rating <- append(rating, ratings)
# To extract votes
votes <- page %>% html_nodes(".sc-53c98e73-0.kRnqtn") %>% html_text() %>% str_extract_all("\\d+") %>% sapply(function(x) as.numeric(paste(x, collapse = "")))
vote <- append(vote, votes)
}
movies_df <- data.frame(title, year, duration, rating, vote)
head(movies_df)
movies_df <- movies_df[order(-movies_df$rating), ]
best_5_movies <- head(movies_df, 5)
print("Best 5 Movies:")
print(best_5_movies)
movies_df <- movies_df[order(-movies_df$rating), ]
worst_5_movies <- tail(movies_df, 5)
print("Worst 5 Movies:")
print(worst_5_movies)
movies_df %>% filter(title == "Aile Arasinda" | title == "Babam ve Oglum" | title == "G.O.R.A." | title == "Pek Yakinda" | title == "Beyaz Melek") %>% arrange(desc(rating))
movie_count_by_year <- movies_df %>%
group_by(year) %>%
summarise(count = n())
ggplot(movie_count_by_year, aes(x = year, y = count)) + geom_point(size = 1) + labs(title = "Number of Movies by Year", x = "Year", y = "Number of Movies")
ggplot(movies_df, aes(x = vote, y = rating)) + geom_point() + labs(x = "Votes", y = "Ratings")
library(tidyverse)
library(stringr)
library(rvest)
url_new <- "https://www.imdb.com/search/title/?groups=top_1000&country_of_origin=TR"
title_new <- c()
year_new <- c()
for (url in url_new) {
page <- read_html(url)
# To extract titles
title_names_new <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names_new <- tail(head(title_names_new, -1), -1)
title_names_new <- str_split(title_names_new, " ", n = 2)
title_names_new <- unlist(lapply(title_names_new, function(x) { x[2] }))
title_new <- append(title_new, title_names_new)
# To extract years
years_new <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year_new <- append(year_new, years_new)
}
movies_df_new <- data.frame(title_new, year_new)
movies_df_new
library(dplyr)
result_df <- left_join(movies_df_new, movies_df, by = c("title_new" = "title"))
print(result_df)
library(dplyr)
ranked_movies_joined <- result_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movies_joined)
library(dplyr)
ranked_movies_initial <- movies_df %>% arrange(desc(rating)) %>% head(11)
print(ranked_movies_initial)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
title <- c()
year <- c()
duration <- c()
rating <- c()
vote <- c()
for (url in sum_url) {
page <- read_html(url)
# To extract names
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) { x[2] }))
title <- append(title, title_names)
# To extract years
years <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year <- append(year, years)
# To convert durations
urations <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text()
durations <- str_extract(durations, "\\d+h( \\d+m)?|\\d+m|\\d+") %>% str_extract("(?<=^.{4}).*")
durations <- hms(durations) # parse to Period object
durations <- minute(durations) # extract total minutes
duration <- append(duration, durations)
# To extract ratings
ratings <- page %>% html_nodes(".sc-43986a27-1.fVmjht") %>% html_text() %>% str_sub(1, 3) %>% as.numeric()
rating <- append(rating, ratings)
# To extract votes
votes <- page %>% html_nodes(".sc-53c98e73-0.kRnqtn") %>% html_text() %>% str_extract_all("\\d+") %>% sapply(function(x) as.numeric(paste(x, collapse = "")))
vote <- append(vote, votes)
}
movies_df <- data.frame(title, year, duration, rating, vote)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
title <- c()
year <- c()
duration <- c()
rating <- c()
vote <- c()
for (url in sum_url) {
page <- read_html(url)
# To extract names
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) { x[2] }))
title <- append(title, title_names)
# To extract years
years <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year <- append(year, years)
# To convert durations
convert_duration_to_minutes <- function(duration_string) {
hours <- as.numeric(str_extract(duration_string, "\\d+\\s?h"))
minutes <- as.numeric(str_extract(duration_string, "\\d+\\s?m"))
seconds <- as.numeric(str_extract(duration_string, "\\d+\\s?s"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
seconds <- ifelse(is.na(seconds), 0, seconds)
total_minutes <- hours * 60 + minutes + seconds / 60
return(total_minutes)
}
# To extract durations
durations <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text()
convert_to_minutes <- function(duration) {
hours <- as.numeric(str_extract(duration, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(duration, "\\d+(?=m)"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_in_minutes <- lapply(durations, function(d) {
d <- str_extract(d, "\\d+h( \\d+m)?|\\d+m|\\d+") %>% str_extract("(?<=^.{4}).*")
convert_to_minutes(d)
})
durations <- unlist(durations_in_minutes)
duration <- append(duration, durations)
# To extract ratings
ratings <- page %>% html_nodes(".sc-43986a27-1.fVmjht") %>% html_text() %>% str_sub(1, 3) %>% as.numeric()
rating <- append(rating, ratings)
# To extract votes
votes <- page %>% html_nodes(".sc-53c98e73-0.kRnqtn") %>% html_text() %>% str_extract_all("\\d+") %>% sapply(function(x) as.numeric(paste(x, collapse = "")))
vote <- append(vote, votes)
}
movies_df <- data.frame(title, year, duration, rating, vote)
head(movies_df)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
title <- c()
year <- c()
duration <- c()
rating <- c()
vote <- c()
for (url in sum_url) {
page <- read_html(url)
# To extract names
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) { x[2] }))
title <- append(title, title_names)
# To extract years
years <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year <- append(year, years)
# To convert durations
convert_duration_to_minutes <- function(duration_string) {
hours <- as.numeric(str_extract(duration_string, "\\d+\\s?h"))
minutes <- as.numeric(str_extract(duration_string, "\\d+\\s?m"))
seconds <- as.numeric(str_extract(duration_string, "\\d+\\s?s"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
seconds <- ifelse(is.na(seconds), 0, seconds)
total_minutes <- hours * 60 + minutes + seconds / 60
return(total_minutes)
}
# To extract durations
durations <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text()
durations_in_minutes <- lapply(durations, function(d) {
d <- str_extract(d, "\\d+h( \\d+m)?|\\d+m|\\d+") %>% str_extract("(?<=^.{4}).*")
convert_to_minutes(d)
})
durations <- unlist(durations_in_minutes)
duration <- append(duration, durations)
# To extract ratings
ratings <- page %>% html_nodes(".sc-43986a27-1.fVmjht") %>% html_text() %>% str_sub(1, 3) %>% as.numeric()
rating <- append(rating, ratings)
# To extract votes
votes <- page %>% html_nodes(".sc-53c98e73-0.kRnqtn") %>% html_text() %>% str_extract_all("\\d+") %>% sapply(function(x) as.numeric(paste(x, collapse = "")))
vote <- append(vote, votes)
}
movies_df <- data.frame(title, year, duration, rating, vote)
head(movies_df)
library(tidyverse)
library(stringr)
library(rvest)
url_1 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250"
url_2 <- "https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250"
sum_url <- c(url_1, url_2)
title <- c()
year <- c()
duration <- c()
rating <- c()
vote <- c()
for (url in sum_url) {
page <- read_html(url)
# To extract names
title_names <- page %>% html_nodes('.ipc-title__text') %>% html_text()
title_names <- tail(head(title_names, -1), -1)
title_names <- str_split(title_names, " ", n = 2)
title_names <- unlist(lapply(title_names, function(x) { x[2] }))
title <- append(title, title_names)
# To extract years
years <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text() %>% str_extract("\\d{4}") %>% as.numeric()
year <- append(year, years)
# To convert durations
convert_to_minutes <- function(duration_string) {
hours <- as.numeric(str_extract(duration_string, "\\d+\\s?h"))
minutes <- as.numeric(str_extract(duration_string, "\\d+\\s?m"))
seconds <- as.numeric(str_extract(duration_string, "\\d+\\s?s"))
hours <- ifelse(is.na(hours), 0, hours)
minutes <- ifelse(is.na(minutes), 0, minutes)
seconds <- ifelse(is.na(seconds), 0, seconds)
total_minutes <- hours * 60 + minutes + seconds / 60
return(total_minutes)
}
# To extract durations
durations <- page %>% html_nodes('.sc-43986a27-7.dBkaPT.dli-title-metadata') %>% html_text()
durations_in_minutes <- lapply(durations, function(d) {
d <- str_extract(d, "\\d+h( \\d+m)?|\\d+m|\\d+") %>% str_extract("(?<=^.{4}).*")
convert_to_minutes(d)
})
durations <- unlist(durations_in_minutes)
duration <- append(duration, durations)
# To extract ratings
ratings <- page %>% html_nodes(".sc-43986a27-1.fVmjht") %>% html_text() %>% str_sub(1, 3) %>% as.numeric()
rating <- append(rating, ratings)
# To extract votes
votes <- page %>% html_nodes(".sc-53c98e73-0.kRnqtn") %>% html_text() %>% str_extract_all("\\d+") %>% sapply(function(x) as.numeric(paste(x, collapse = "")))
vote <- append(vote, votes)
}
movies_df <- data.frame(title, year, duration, rating, vote)
head(movies_df)
